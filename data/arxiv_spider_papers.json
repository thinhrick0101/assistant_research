[
  {
    "paper_id": "2407.21059v1",
    "title": "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks",
    "authors": [
      "Yunfan Gao",
      "Yun Xiong",
      "Meng Wang",
      "Haofen Wang"
    ],
    "abstract": "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\nincreasing demands of application scenarios have driven the evolution of RAG,\nleading to the integration of advanced retrievers, LLMs and other complementary\ntechnologies, which in turn has amplified the intricacy of RAG systems.\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\nwith many methods struggling to be unified under the process of\n\"retrieve-then-generate\". In this context, this paper examines the limitations\nof the existing RAG paradigm and introduces the modular RAG framework. By\ndecomposing complex RAG systems into independent modules and specialized\noperators, it facilitates a highly reconfigurable framework. Modular RAG\ntranscends the traditional linear architecture, embracing a more advanced\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\nextensive research, this paper further identifies prevalent RAG\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\nanalysis of their respective implementation nuances. Modular RAG presents\ninnovative opportunities for the conceptualization and deployment of RAG\nsystems. Finally, the paper explores the potential emergence of new operators\nand paradigms, establishing a solid theoretical foundation and a practical\nroadmap for the continued evolution and practical deployment of RAG\ntechnologies.",
    "url": "http://arxiv.org/abs/2407.21059v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21059v1",
    "published_date": "2024-07-26",
    "source": "arxiv",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ]
  },
  {
    "paper_id": "2501.00353v1",
    "title": "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented Instructions",
    "authors": [
      "Wanlong Liu",
      "Junying Chen",
      "Ke Ji",
      "Li Zhou",
      "Wenyu Chen",
      "Benyou Wang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for\nenhancing large language models (LLMs) by incorporating external knowledge.\nHowever, current RAG methods face two limitations: (1) they only cover limited\nRAG scenarios. (2) They suffer from limited task diversity due to the lack of a\ngeneral RAG dataset. To address these limitations, we propose RAG-Instruct, a\ngeneral method for synthesizing diverse and high-quality RAG instruction data\nbased on any source corpus. Our approach leverages (1) five RAG paradigms,\nwhich encompass diverse query-document relationships, and (2) instruction\nsimulation, which enhances instruction diversity and quality by utilizing the\nstrengths of existing instruction datasets. Using this method, we construct a\n40K instruction dataset from Wikipedia, comprehensively covering diverse RAG\nscenarios and tasks. Experiments demonstrate that RAG-Instruct effectively\nenhances LLMs' RAG capabilities, achieving strong zero-shot performance and\nsignificantly outperforming various RAG baselines across a diverse set of\ntasks. RAG-Instruct is publicly available at\nhttps://github.com/FreedomIntelligence/RAG-Instruct.",
    "url": "http://arxiv.org/abs/2501.00353v1",
    "pdf_url": "http://arxiv.org/pdf/2501.00353v1",
    "published_date": "2024-12-31",
    "source": "arxiv",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "paper_id": "2501.05249v1",
    "title": "RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models",
    "authors": [
      "Peizhuo Lv",
      "Mengjie Sun",
      "Hao Wang",
      "Xiaofeng Wang",
      "Shengzhi Zhang",
      "Yuxuan Chen",
      "Kai Chen",
      "Limin Sun"
    ],
    "abstract": "In recent years, tremendous success has been witnessed in Retrieval-Augmented\nGeneration (RAG), widely used to enhance Large Language Models (LLMs) in\ndomain-specific, knowledge-intensive, and privacy-sensitive tasks. However,\nattackers may steal those valuable RAGs and deploy or commercialize them,\nmaking it essential to detect Intellectual Property (IP) infringement. Most\nexisting ownership protection solutions, such as watermarks, are designed for\nrelational databases and texts. They cannot be directly applied to RAGs because\nrelational database watermarks require white-box access to detect IP\ninfringement, which is unrealistic for the knowledge base in RAGs. Meanwhile,\npost-processing by the adversary's deployed LLMs typically destructs text\nwatermark information. To address those problems, we propose a novel black-box\n\"knowledge watermark\" approach, named RAG-WM, to detect IP infringement of\nRAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark\nGenerator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark\ntexts based on watermark entity-relationship tuples and inject them into the\ntarget RAG. We evaluate RAG-WM across three domain-specific and two\nprivacy-sensitive tasks on four benchmark LLMs. Experimental results show that\nRAG-WM effectively detects the stolen RAGs in various deployed LLMs.\nFurthermore, RAG-WM is robust against paraphrasing, unrelated content removal,\nknowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also\nevade watermark detection approaches, highlighting its promising application in\ndetecting IP infringement of RAG systems.",
    "url": "http://arxiv.org/abs/2501.05249v1",
    "pdf_url": "http://arxiv.org/pdf/2501.05249v1",
    "published_date": "2025-01-09",
    "source": "arxiv",
    "categories": [
      "cs.CR",
      "cs.AI"
    ]
  },
  {
    "paper_id": "2409.01666v1",
    "title": "In Defense of RAG in the Era of Long-Context Language Models",
    "authors": [
      "Tan Yu",
      "Anbang Xu",
      "Rama Akkiraju"
    ],
    "abstract": "Overcoming the limited context limitations in early-generation LLMs,\nretrieval-augmented generation (RAG) has been a reliable solution for\ncontext-based answer generation in the past. Recently, the emergence of\nlong-context LLMs allows the models to incorporate much longer text sequences,\nmaking RAG less attractive. Recent studies show that long-context LLMs\nsignificantly outperform RAG in long-context applications. Unlike the existing\nworks favoring the long-context LLM over RAG, we argue that the extremely long\ncontext in LLMs suffers from a diminished focus on relevant information and\nleads to potential degradation in answer quality. This paper revisits the RAG\nin long-context answer generation. We propose an order-preserve\nretrieval-augmented generation (OP-RAG) mechanism, which significantly improves\nthe performance of RAG for long-context question-answer applications. With\nOP-RAG, as the number of retrieved chunks increases, the answer quality\ninitially rises, and then declines, forming an inverted U-shaped curve. There\nexist sweet points where OP-RAG could achieve higher answer quality with much\nless tokens than long-context LLM taking the whole context as input. Extensive\nexperiments on public benchmark demonstrate the superiority of our OP-RAG.",
    "url": "http://arxiv.org/abs/2409.01666v1",
    "pdf_url": "http://arxiv.org/pdf/2409.01666v1",
    "published_date": "2024-09-03",
    "source": "arxiv",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "paper_id": "2502.20995v1",
    "title": "The RAG Paradox: A Black-Box Attack Exploiting Unintentional Vulnerabilities in Retrieval-Augmented Generation Systems",
    "authors": [
      "Chanwoo Choi",
      "Jinsoo Kim",
      "Sukmin Cho",
      "Soyeong Jeong",
      "Buru Chang"
    ],
    "abstract": "With the growing adoption of retrieval-augmented generation (RAG) systems,\nrecent studies have introduced attack methods aimed at degrading their\nperformance. However, these methods rely on unrealistic white-box assumptions,\nsuch as attackers having access to RAG systems' internal processes. To address\nthis issue, we introduce a realistic black-box attack scenario based on the RAG\nparadox, where RAG systems inadvertently expose vulnerabilities while\nattempting to enhance trustworthiness. Because RAG systems reference external\ndocuments during response generation, our attack targets these sources without\nrequiring internal access. Our approach first identifies the external sources\ndisclosed by RAG systems and then automatically generates poisoned documents\nwith misinformation designed to match these sources. Finally, these poisoned\ndocuments are newly published on the disclosed sources, disrupting the RAG\nsystem's response generation process. Both offline and online experiments\nconfirm that this attack significantly reduces RAG performance without\nrequiring internal access. Furthermore, from an insider perspective within the\nRAG system, we propose a re-ranking method that acts as a fundamental\nsafeguard, offering minimal protection against unforeseen attacks.",
    "url": "http://arxiv.org/abs/2502.20995v1",
    "pdf_url": "http://arxiv.org/pdf/2502.20995v1",
    "published_date": "2025-02-28",
    "source": "arxiv",
    "categories": [
      "cs.CR",
      "cs.IR"
    ]
  },
  {
    "paper_id": "2401.15391v1",
    "title": "MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries",
    "authors": [
      "Yixuan Tang",
      "Yi Yang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) augments large language models (LLM) by\nretrieving relevant knowledge, showing promising potential in mitigating LLM\nhallucinations and enhancing response quality, thereby facilitating the great\nadoption of LLMs in practice. However, we find that existing RAG systems are\ninadequate in answering multi-hop queries, which require retrieving and\nreasoning over multiple pieces of supporting evidence. Furthermore, to our\nknowledge, no existing RAG benchmarking dataset focuses on multi-hop queries.\nIn this paper, we develop a novel dataset, MultiHop-RAG, which consists of a\nknowledge base, a large collection of multi-hop queries, their ground-truth\nanswers, and the associated supporting evidence. We detail the procedure of\nbuilding the dataset, utilizing an English news article dataset as the\nunderlying RAG knowledge base. We demonstrate the benchmarking utility of\nMultiHop-RAG in two experiments. The first experiment compares different\nembedding models for retrieving evidence for multi-hop queries. In the second\nexperiment, we examine the capabilities of various state-of-the-art LLMs,\nincluding GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop\nqueries given the evidence. Both experiments reveal that existing RAG methods\nperform unsatisfactorily in retrieving and answering multi-hop queries. We hope\nMultiHop-RAG will be a valuable resource for the community in developing\neffective RAG systems, thereby facilitating greater adoption of LLMs in\npractice. The MultiHop-RAG and implemented RAG system is publicly available at\nhttps://github.com/yixuantt/MultiHop-RAG/.",
    "url": "http://arxiv.org/abs/2401.15391v1",
    "pdf_url": "http://arxiv.org/pdf/2401.15391v1",
    "published_date": "2024-01-27",
    "source": "arxiv",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "paper_id": "2410.07176v1",
    "title": "Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models",
    "authors": [
      "Fei Wang",
      "Xingchen Wan",
      "Ruoxi Sun",
      "Jiefeng Chen",
      "Sercan Ö. Arık"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG), while effective in integrating external\nknowledge to address the limitations of large language models (LLMs), can be\nundermined by imperfect retrieval, which may introduce irrelevant, misleading,\nor even malicious information. Despite its importance, previous studies have\nrarely explored the behavior of RAG through joint analysis on how errors from\nimperfect retrieval attribute and propagate, and how potential conflicts arise\nbetween the LLMs' internal knowledge and external sources. We find that\nimperfect retrieval augmentation might be inevitable and quite harmful, through\ncontrolled analysis under realistic conditions. We identify the knowledge\nconflicts between LLM-internal and external knowledge from retrieval as a\nbottleneck to overcome in the post-retrieval stage of RAG. To render LLMs\nresilient to imperfect retrieval, we propose Astute RAG, a novel RAG approach\nthat adaptively elicits essential information from LLMs' internal knowledge,\niteratively consolidates internal and external knowledge with source-awareness,\nand finalizes the answer according to information reliability. Our experiments\nusing Gemini and Claude demonstrate that Astute RAG significantly outperforms\nprevious robustness-enhanced RAG methods. Notably, Astute RAG is the only\napproach that matches or exceeds the performance of LLMs without RAG under\nworst-case scenarios. Further analysis reveals that Astute RAG effectively\nresolves knowledge conflicts, improving the reliability and trustworthiness of\nRAG systems.",
    "url": "http://arxiv.org/abs/2410.07176v1",
    "pdf_url": "http://arxiv.org/pdf/2410.07176v1",
    "published_date": "2024-10-09",
    "source": "arxiv",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "paper_id": "2410.13509v2",
    "title": "RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards",
    "authors": [
      "Xinze Li",
      "Sen Mei",
      "Zhenghao Liu",
      "Yukun Yan",
      "Shuo Wang",
      "Shi Yu",
      "Zheni Zeng",
      "Hao Chen",
      "Ge Yu",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Chenyan Xiong"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has proven its effectiveness in\nmitigating hallucinations in Large Language Models (LLMs) by retrieving\nknowledge from external resources. To adapt LLMs for the RAG systems, current\napproaches use instruction tuning to optimize LLMs, improving their ability to\nutilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses\non equipping LLMs to handle diverse RAG tasks using different instructions.\nHowever, it trains RAG modules to overfit training signals and overlooks the\nvarying data preferences among agents within the RAG system. In this paper, we\npropose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG\nsystems by aligning data preferences between different RAG modules. DDR works\nby collecting the rewards to optimize each agent in the RAG system with the\nrollout method, which prompts agents to sample some potential responses as\nperturbations, evaluates the impact of these perturbations on the whole RAG\nsystem, and subsequently optimizes the agent to produce outputs that improve\nthe performance of the RAG system. Our experiments on various\nknowledge-intensive tasks demonstrate that DDR significantly outperforms the\nSFT method, particularly for LLMs with smaller-scale parameters that depend\nmore on the retrieved knowledge. Additionally, DDR exhibits a stronger\ncapability to align the data preference between RAG modules. The DDR method\nmakes the generation module more effective in extracting key information from\ndocuments and mitigating conflicts between parametric memory and external\nknowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.",
    "url": "http://arxiv.org/abs/2410.13509v2",
    "pdf_url": "http://arxiv.org/pdf/2410.13509v2",
    "published_date": "2024-10-17",
    "source": "arxiv",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "paper_id": "2401.05856v1",
    "title": "Seven Failure Points When Engineering a Retrieval Augmented Generation System",
    "authors": [
      "Scott Barnett",
      "Stefanus Kurniawan",
      "Srikanth Thudumu",
      "Zach Brannelly",
      "Mohamed Abdelrazek"
    ],
    "abstract": "Software engineers are increasingly adding semantic search capabilities to\napplications using a strategy known as Retrieval Augmented Generation (RAG). A\nRAG system involves finding documents that semantically match a query and then\npassing the documents to a large language model (LLM) such as ChatGPT to\nextract the right answer using an LLM. RAG systems aim to: a) reduce the\nproblem of hallucinated responses from LLMs, b) link sources/references to\ngenerated responses, and c) remove the need for annotating documents with\nmeta-data. However, RAG systems suffer from limitations inherent to information\nretrieval systems and from reliance on LLMs. In this paper, we present an\nexperience report on the failure points of RAG systems from three case studies\nfrom separate domains: research, education, and biomedical. We share the\nlessons learned and present 7 failure points to consider when designing a RAG\nsystem. The two key takeaways arising from our work are: 1) validation of a RAG\nsystem is only feasible during operation, and 2) the robustness of a RAG system\nevolves rather than designed in at the start. We conclude with a list of\npotential research directions on RAG systems for the software engineering\ncommunity.",
    "url": "http://arxiv.org/abs/2401.05856v1",
    "pdf_url": "http://arxiv.org/pdf/2401.05856v1",
    "published_date": "2024-01-11",
    "source": "arxiv",
    "categories": [
      "cs.SE",
      "cs.AI"
    ]
  },
  {
    "paper_id": "2404.00657v1",
    "title": "Observations on Building RAG Systems for Technical Documents",
    "authors": [
      "Sumit Soman",
      "Sujoy Roychowdhury"
    ],
    "abstract": "Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.",
    "url": "http://arxiv.org/abs/2404.00657v1",
    "pdf_url": "http://arxiv.org/pdf/2404.00657v1",
    "published_date": "2024-03-31",
    "source": "arxiv",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ]
  }
]